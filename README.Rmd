---
title: "OVtool - Omitted Variable tool"
author: Joseph D. Pane, Beth Ann Griffin, Lane F. Burgette, and Daniel F. McCaffrey
output: html_document
header-includes:
- \usepackage[T1]{fontenc}
- \usepackage{courier}
---

```{r setup, include=F}
# github_document
# html_document
# word_document
# pdf_document
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
time = Sys.time()
```

*Note: This is a work in progress.. This document was lasted upated `r time`*

# Introduction

The <ins>O</ins>mitted <ins>V</ins>ariable <ins>T</ins>ool (`OVtool`) package was designed to assess the sensitivity of research findings to omitted variables when estimating causal effects using propensity score (PS) weighting. This package includes graphics and summary results that will enable a researcher to quantify the impact an omitted variable would have on their results. Burgette et al. (in preparation) describe the methodology behind the primary function in this package, `ov_sim()`. This document presents syntax for the implementation of the `ov_sim()` function and provides an example of how to interpret the packages' graphical output.

This package is useful in a wide range of applications where researchers want to analyze how sensitive their research findings are to unobserved confounders that were not included in their propensity score and outcome models. It will estimate the potential impact of the unobserved counfounders on both the estimated treatment or exposure effects as well as on the statistical significance of an analysis.

# Example: Synthetic Data 

This package is demonstrated using a synthetic data set that was derived from a large scale observational study on youth in substance use treatment. More specifically, it contains a subset of measures from the Global Appraisal of Individual Needs biopsychosocial assessment instrument (GAIN) (Dennis, Titus et al. 2003) from sites that adminstered two different types of substance use disorder treatments (treatment "A" and treatment "B"). The Center for Substance Abuse Treatment (CSAT) funded the sites that administered these two SUD treatments. This dataset consists of 4,000 adolescents. The main goal of this analysis is to understand the effect Treatment A and Treatment B, indicated by `treat`, have on mental health outcomes and to assess the potential for an omitted variable to bias the findings. To create our synthetic data set, we used an R package called "[synthpop](https://cran.r-project.org/web/packages/synthpop/vignettes/synthpop.pdf ) : Bespoke Creation of Synthetic Data in R". 

In our synthetic dataset, there are 2,000 adolescents in each treatment group. Within this dataset there are variables on substance use disorder and mental health outcomes. For this tutorial we are particularly interested in the mental health outcome, `eps7p_3`, emotional problem scale (eps) recorded at three months. Higher values of eps indicate more emotional problems. Substance use researchers are particularly interested in whether or not treatment A reduces emotional problems more than treatment B. `eps7p_3` ranges from zero to one, where higher values of EPS indicate more emotional problems. See (Dennis, 2003) for more details on this scale. 

Past research has indicated there are many influential confounders when analyzing adolescents' emotional problems, some included in this synthetic dataset (Diamond et al.). These variables were measured at baseline: emotional problem scale (`eps7p_0`), adjusted days abstinent (any in past 90) (`ada_0`), substance frequency scale (`sfs8p_0`), substance abuse treatment index (`sati_0`), in recovery (`recov_0`), traumatic stress scale (`tss_0`), mental health treatment in the past 90 days (`mhtrt_0`), and the depressive symptom scale (`dss9_0`). \newline

We begin by loading the development version of the package from [GitHub](https://github.com/). If you haven't installed the devtools package, make sure you uncomment and run the first line of the following code snippet prior to running the second line:

```{r, begin, message=F}
# install.packages("devtools")
devtools::install_github("jpane24/OVtool", ref="temporary")
library(OVtool)
```

We can load the synthetic dataset and make our treatment variable a binary indicator of 0's and 1's:

```{r, data}
data(sud) 
sud$treat = ifelse(sud$treat == "A", 1, 0)
```

The relevant variables in this analysis are:

* **Treatment indicator** `treat`: indicates treatment type where 1 is Treatment "A" and 0 is Treatment "B"

* **Outcome of interest** `eps7p_3`: emotional problem scale at 3-months

* `eps7p_0`: emotional problem scale at baseline

* `sfs8p_0`: substance frequency scale 8-item version at baseline

* `sati_0`: substance abuse treatment index at baseline

* `ada_0`: adjusted days abstinent at baseline

* `recov_0`: indicates whether the adolescent was in recovery at baseline, where 1 is in recovery and 0 is not in recovery

* `tss_0`: traumatic stress scale at baseline

* `mhtrt_0`: mental health treatment in the past 90 days at baseline

* `dss9_0`: depressive symptom scale at baseline

In the next section, we will show how our method works with the average treatment effect (ATE) using a continuous outcome. The OVtool also handles binary outcomes and weights that were estimated using the average treatment effect on the treated (ATT) estimand.

## Continous Outcome: Average Treatment Effect (ATE)

The `OVtool` can either take a vector of weights estimated using any method or a ps object produced by `TWANG` (Ridgeway et al., 2020). We begin walking through the OVtool by estimating weights using `ps()` from the `TWANG` package prior to running the outcome model using `outcome_model()` from the `OVtool` package. The `outcome_model` function calls `svyglm` from the `survey` package in R ([survey](http://cran.fhcrc.org/web/packages/survey/vignettes/survey.pdf)) to produce outcome model results. The chunk of code below demonstrates how to specify your propensity score model and generate your propensity score weights using the `TWANG` package.

```{r, estTWANG}
## Create Formula
my_formula = as.formula(treat ~ eps7p_0 + sfs8p_0 + sati_0 + ada_0 + recov_0 + 
                          tss_0 + mhtrt_0 + dss9_0)

## Get weights
sud = data.frame(sud)
library(twang)
ps.twang <- ps(my_formula, data = sud, estimand = 'ATE', booster = "gbm",
               stop.method = "ks.max", verbose=F, ks.exact = T)

# Check Balance
bal.table(ps.twang); # summary(ps.twang)
```

The output produced by the code snippet above demonstrates that `TWANG` does a reasonable job of balancing. There are additional diagnostics we could check to ensure we have good balance but we move on without diving in further because the purpose of this tutorial is to showcase `OVtool`. See [Ridgeway et al.](https://cran.r-project.org/web/packages/twang/vignettes/twang.pdf) for further information on balance diagnostics. The next step is to estimate the treatment effect and analyze the sensitivity of those results using `OVtool`. We first present how a researcher would produce results for their outcome model. There are two options the researcher can take to input the relevant information to get their outcome results using `outcome_model()`. 

* Input a `ps.object` from `TWANG` and a `stop.method` (e.g. `"ks.max"`)
or
* Input a vector of `weights`, a data frame containing the `data` used, and the column name representing the treatment indicator, `treatment`. 

The analyst must also provide a column name representing the outcome and a vector of covariates to be included in the final outcome model. Recall: `outcome_model()` calls `svyglm()` from the survey package to run the outcome model.

```{r, outcomemodel}
# Get weights (not needed if user inserts a ps object in OVTool)
sud$w_twang = ps.twang$w$ks.max.ATE

# Run Models -- first standardize outcome
sud$eps7p_3_std = sud$eps7p_3/sd(sud$eps7p_3) 

# Run outcome model (function in OVtool that calls survey::svyglm)
results = outcome_model(ps_object = NULL,
                        stop.method = NULL, 
                        data = sud,
                        weights = sud$w_twang, 
                        treatment = "treat",
                        outcome = "eps7p_3_std", 
                        model_covariates = c("eps7p_0", "sfs8p_0",
                                             "sati_0", "ada_0",
                                             "recov_0", "tss_0",
                                             "mhtrt_0", "dss9_0"),
                        estimand = "ATE")

summary(results$mod_results)
```

The outcome model results show an adjusted treatment effect estimate that accounts for confounding from observed covariates between youth in the two treatment programs (A = 1 and B = 0). From the results, we can see that the effect size is 0.079 (p = 0.004), whereby youth receiving treatment A have slightly higher emotional problems at the 3-month follow-up than youth in treatment program B. 

At this stage, researchers should begin to ask themselves if this effect is real and how sensitive it is. Our tool is used to help answer these sort of logical next step questions. The next snippet of code presents the main function in `OVtool`: `ov_sim()`. This function requires results from `outcome_model()` plus additional parameters including:

* `weight_covariates`: a vector of column names representing the covariates used to produce the analysts propensity score weights (these may or may not be the same as the list of covariates used for the outcome model)

* `es_grid`: a vector on an effect size scale representing the association between the unobserved confounders (omitted variables) and the treatment indicator

* `rho_grid`: a vector of correlations to simulate over. These correlations represent the correlation between the omitted variable and the outcome

* `n_reps`: the number of repetitions represents the number of times an unobserved confounder is simulated at each effect size and rho combination. The package defaults to 50. Fifty repetitions should be sufficient but the analyst may need to reduce or increase the number of repetitions.

The grid, as shown by the x-axis and y-axis in Figure 1 presents the effect size and rho, respectively. We define the effect size on the x-axis to show the strength of the relationship between the simulated unobserved covariate (U) and the treatment group indicator; it is defined as the standardized mean difference in U for the treatment A and treatment B groups. Typical rules of thumb for effect sizes (Cohen's D) follow such that effect sizes greater than 0.2 would be considered small, 0.4 would be moderate and 0.6 would be large (Cohen, J., 1995). We define rho in this setting as the absolute correlation the unobserved covariate (U) has with the outcome of interest, with larger values indicating stronger relationships between U and the outcome. Please see Burgette et al. (in progress) for additional details on the methodology used by `OVtool`.  

```{r, ov_sim}
# Run OVtool (with weights (not a ps object))
ovtool_results_twang = ov_sim(model_results=results, 
                              weight_covariates=c("eps7p_0", "sfs8p_0",
                                                  "sati_0", "ada_0",
                                                  "recov_0", "tss_0", 
                                                  "mhtrt_0", "dss9_0"),
                              es_grid = NULL,
                              rho_grid = seq(0, 0.40, by = 0.05),
                              n_reps=25,
                              progress = TRUE)
```

In our example, `ov_sim` produced a warning stating ties in the outcome variable may be problematic. This warning allows the user to continue with their analysis but it is important for the analyst to understand that when generating the omitted variable (U), the empirical cumulative distribution function (CDF) for the outcome within each treatment is used. Many ties could lead to issues. Additionally, a note was printed to the screen informing the user that the tool expanded the size of the grid because the maximum rho value specified (0.4) was less than the maximum absolute correlation an observed covariate has with the outcome. To allow all observed covariates' effect size and rho values to be plotted on the second and third graphics, the tool autmatically will expand the rho grid. The grid values are not required; if es_grid and/or rho_grid is set to `NULL`, the tool will calculate reasonable values to simulate over. In other words, the tool will iterate over all observed covariate associations with the treatment indicator on an effect size scale to derive a reasonable range.

A key assumption in this tool is the omitted variable is independent from all covariates included in the propensity score model; this assumption may result in correlations of the omitted variable that have a maximum bound below moderately sized correlations and results in unstable contour estimates outside of a particular threshold. Often the user will be able to observe this point because the contours will become unsmooth. Burgette et al. explain the implications of this assumption.

To visualize our results, the `plot.ov` function will produce three graphics. The first graphic (Figure 1) plots the treatment effect contours without covariate labels. If the user specifies the parameter `col` as `"color"`, the contours will overlay a colored heat map. The second graphic (Figure 2) plots the p-value contours with the column names submitted to `weight_covariates` plotted by their raw rho and effect size. The third graphic (Figure 3) plots the treatment effect contours with the p-value contour overlayed and covariate labels. The `col` options for Figures 2 and 3 are `"bw"` and `"color"` which produce a black and white and colored contour graphic, respectively.

```{r, fig1, fig.width=10, fig.height=7, fig.align='center', warning=F}
plot.ov(ovtool_results_twang, print_graphic = "1", col = "bw")
```

The y-axis in Figure 1 represents the unobserved confounder's absolute correlation with the outcome and the x-axis is the association between the unobserved confounder and the treatment indicator on an effect size scale. The black lines represent effect size contours that run along the grid. The PS weighted treatment effect of Treatment A versus Treatment B equals 0.079 and is significant with a p-value equal to 0.004. However, looking at this graphic alone will not give us an idea of how sensitive the effect is. \newline

```{r, fig2, fig.width=10, fig.height=7, fig.align='center', linewidth=100}
plot.ov(ovtool_results_twang, print_graphic = "2", col = "color")
```

Figure 2 is a different variation of Figure 1, but only shows the p-value contours with an additional dimension, covariate labels.  Recall: if a covariate had a raw correlation that was outside the range of the graphic limits, the tool informed the user that the rho grid was expanded. The blue dots and their labels on the plot represent the observed covariates correlations with the outcome (y-axis) and treatment indicator (x-axis). For instance, `ada_0` and the outcome have approximately a 0.18 absolute correlation with the emotional problem scale at three months and an absolute association of approximately 0.17 effect size difference between the two treatment groups (magnitude of its relationship with the treatment indicator). In this case, not all of the observed covariate relationships with the outcome and the treatment indicator are to the right of the 0.05 p-value threshold so the analyst potentially has results that are sensitive to an unobserved confounder. If the blue points all existed to the right of the 0.05 p-value contour, then unobserved confounders with similar associations would retain the significant effect and allow the user to conclude that the results are reasonably robust. \newline

*Note: When the outcome model shows a significant effect, for all observed covariates, regardless of the sign of the association effect size difference between the two treatment groups, we force the sign of the magnitude to go with the direction of the significant effect. The blue points are meant to give the analyst an idea (using observed covariates as an indicator) of what would cause a change in the interpretation of their results.*

```{r, fig3, fig.width=10, fig.height=7, fig.align='center', linewidth=100}
plot.ov(ovtool_results_twang, print_graphic = "3", col = "color")
```
Figure 3, combines Figure 1 and Figure 2 into one graphic. Again, the y-axis in Figure 3 still represents rho, the absolute value of the correlation between the right-hand side variable and the outcome. The x-axis represents the association with the treatment indicator on the effect size scale. Plotted at the bottom of the figure margin is the PS weighted treatment effect size  (0.079) and associated p-value of 0.004. The solid black contours represent the effect size (treatment effect) contour lines and the red lines (sometimes dashed) represent the p-value threshold. The key on the right side of the graphic shows where various p-value cutoff lines are, including p = 0.05. The blue points on the plot represent the observed covariate correlations with the outcome and effect size associations with the treatment indicator (e.g., standardized mean difference on the given covariates
between the two groups). 

Finally, we can interpret this graphic by running the summary command on the ov object:

```{r, summary`, linewidth=100}
summary.ov(OVtool_results = ovtool_results_twang, model_results = results)
```

The `OVtool` gives a recommendation on how to report findings regarding the direction of the treatment effect and statistical significance. An analyst could take the results produced by `summary.ov()` and plug them into a manuscript. In summary, the sign of the estimated effect is expected to remain consistent when simulated unobserved confounders have the same strength of association with the treatment indicator and outcome that are seen in the observed confounders. In the most extreme observed case, the estimated effect size is reduced by 69 percent. However, statistical significance at the 0.05 level is only expected to be robust to unobserved confounders with strengths of associations with the treatment indicator and outcome that are seen in 5 of the 8 observed confounders. In the most extreme observed case, the p-value would be
expected to increase from 0.004 to 0.405. Significance at the 0.05 level would not be expected to be preserved for unobserved confounders that have the same strength of association with the treatment indicator and outcome as `eps7p_0`, `sati_0`, `tss_0`.

# Conclusion

There is continuously a call for work on assessing the sensitivity of research findings. To our knowledge, this is a novel approach to assessing the sensitivity of research findings to omitted variables when estimating causal effects using PS weighting. Development of user friendly software tools are critical for advancing research. We hope that users will use our tool when they are trying to analyze how sensitive their results are to omitted variables when estimating causal effects using ps methods.

# Acknowledgements

The devlopment of this tutorial was funded by the National Institute of Health (R01DA045049; PIs: Griffin/McCaffrey). We thank (fill in). This tutorial uses a synthetic dataset of youth receiving two unidentified treatments from the GAIN; running on the true dataset will produce different results.

# References

*Will update to link with text*

Cohen, J. (1995). The earth is round (p < .05): Rejoinder. American Psychologist, 50, 1103.

Diamond, G., Godley, S. H., Liddle, H. A., Sampl, S., Webb, C., Tims, F. M., & Meyers, R. (2002). Five outpatient treatment models for adolescent marijuana use: a description of the Cannabis Youth Treatment Interventions. Addiction, 97, 70-83. 

Lumley, T (2020). "survey: analysis of complex survey samples." R package version 4.0.

McCaffrey, D. F., Ridgeway, G., and Morral, A. R. (2004). Propensity score
estimation with boosted regression for evaluating causal effects in observational studies. Psychological methods 9, 403.

Ridgeway, G., McCaffrey, D., Morral, A., Burgette, L., and Griffin, B. A. (2020).
Toolkit for Weighting and Analysis of Nonequivalent Groups: A tutorial for
the twang package. Santa Monica, CA: RAND Corporation.

